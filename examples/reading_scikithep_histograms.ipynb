{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading histograms\n",
    "\n",
    "For the new python-based frameworks, another common format would needs\n",
    "translation are histogram in the\n",
    "[`scikit-hep.hist`](https://hist.readthedocs.io/en/latest/). The functions in\n",
    "the `hepdata_lib.hist_utils` will help you with that, and this notebook will\n",
    "demonstrate how to do that.\n",
    "\n",
    "As explained in the [Getting started notebook](Getting_started.ipynb), a\n",
    "`Submission` needs to exist or be created. Here, we'll just create one without\n",
    "any additional information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/04\n"
     ]
    }
   ],
   "source": [
    "from hepdata_lib import Submission\n",
    "\n",
    "submission = Submission()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The common use-case for `scikit-hep` histograms is to allow for after-the-fact\n",
    "slicing and grouping from a primary histogram. Let us first generate a fake\n",
    "histogram that may appear in common histograms, as well as a common slicing\n",
    "routine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hist(\n",
       "  StrCategory(['data', 'QCD', 'ttbar'], name='dataset'),\n",
       "  IntCategory([-1, 0, 4, 5], name='flavor'),\n",
       "  Regular(10, -3, 3, name='eta'),\n",
       "  Regular(10, 0, 500, name='pt'),\n",
       "  storage=Weight()) # Sum: WeightedSum(value=221221, variance=123802) (WeightedSum(value=256973, variance=143935) with flow)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hist\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=123_456_789)\n",
    "\n",
    "h = hist.Hist(\n",
    "    hist.axis.StrCategory([\"data\", \"QCD\", \"ttbar\"], name=\"dataset\"),\n",
    "    hist.axis.IntCategory([-1, 0, 4, 5], name=\"flavor\"),\n",
    "    hist.axis.Regular(10, -3, +3, name=\"eta\"),\n",
    "    hist.axis.Regular(10, 0, 500, name=\"pt\"),\n",
    "    storage=hist.storage.Weight(),\n",
    ")\n",
    "\n",
    "h.fill(  ## For mock data\n",
    "    dataset=\"data\",\n",
    "    flavor=-1,\n",
    "    eta=rng.normal(0, 2.0, size=123_456),\n",
    "    pt=rng.exponential(100, size=123_456),\n",
    ")\n",
    "h.fill(  ## For Mock QCD\n",
    "    dataset=\"QCD\",\n",
    "    flavor=rng.choice([0, 4, 5], size=1_000_000, p=[0.8, 0.15, 0.05]),\n",
    "    eta=rng.normal(0.0, 2.0, size=1_000_000),\n",
    "    pt=rng.exponential(100, size=1_000_000),\n",
    "    weight=0.123456 * 2 * rng.random(size=1_000_000),\n",
    ")\n",
    "h.fill(  ## For mock ttbar\n",
    "    dataset=\"ttbar\",\n",
    "    flavor=rng.choice([0, 4, 5], size=1_000_000, p=[0.45, 0.1, 0.45]),\n",
    "    eta=rng.normal(0.0, 1.5, size=1_000_000),\n",
    "    pt=rng.exponential(200, size=1_000_000),\n",
    "    weight=0.01 * 2 * rng.random(size=1_000_000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of manual processing to 1D array\n",
    "\n",
    "Let use create a simple slicing routine to get the various histograms of\n",
    "interest, then use the most general function, the\n",
    "`hepdata_lib.hist_utils.read_hist` method, to create arrays that will be\n",
    "compatible with `hepdata_lib.Variable` declaration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hist_value': array([48787., 29325., 17947., 10685.,  6569.,  4067.,  2400.,  1485.,\n",
      "         886.,   524.]),\n",
      " 'hist_variance': array([48787., 29325., 17947., 10685.,  6569.,  4067.,  2400.,  1485.,\n",
      "         886.,   524.]),\n",
      " 'pt': array([(  0.,  50.), ( 50., 100.), (100., 150.), (150., 200.),\n",
      "       (200., 250.), (250., 300.), (300., 350.), (350., 400.),\n",
      "       (400., 450.), (450., 500.)], dtype=[('f0', '<f4'), ('f1', '<f4')])}\n"
     ]
    }
   ],
   "source": [
    "from hepdata_lib.hist_utils import read_hist\n",
    "import pprint\n",
    "\n",
    "data_hist = h[dict(dataset=\"data\", flavor=sum, eta=sum)]\n",
    "fqcd_hist = (\n",
    "    h[dict(dataset=\"QCD\", flavor=sum, eta=slice(1.4j, None, sum))]\n",
    "    + h[dict(dataset=\"QCD\", flavor=sum, eta=slice(None, -1.4j, sum))]\n",
    ")\n",
    "cqcd_hist = h[dict(dataset=\"QCD\", flavor=sum, eta=slice(-1.4j, 1.4j, sum))]\n",
    "tt_b_hist = h[dict(dataset=\"ttbar\", flavor=4j, eta=sum)]\n",
    "tt_l_hist = h[dict(dataset=\"ttbar\", flavor=0j, eta=sum)]\n",
    "\n",
    "tab_data = read_hist(data_hist)\n",
    "tab_fqcd = read_hist(fqcd_hist)\n",
    "tab_cqcd = read_hist(cqcd_hist)\n",
    "tab_tt_b = read_hist(tt_b_hist)\n",
    "tab_tt_l = read_hist(tt_l_hist)\n",
    "\n",
    "pprint.pprint(tab_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All axes remaining will generate a corresponding array that can be used to\n",
    "declare `Variable` instances. Because the histogram was declared with\n",
    "`storage=Weight`, entries for `hist_value` (sum of weights) and `hist_variance`\n",
    "(sum of weight-squared) will be presented to the user. This information can the\n",
    "be used for the uncertainty generation. A simple example is shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepdata_lib import Table, Variable, Uncertainty\n",
    "import hist.intervals\n",
    "\n",
    "tab1d = Table(\"my table\")\n",
    "\n",
    "var = Variable(\"Jet pT\", is_independent=True, is_binned=True, units=\"GeV\")\n",
    "var.values = tab_data[\"pt\"]\n",
    "tab1d.add_variable(var)\n",
    "\n",
    "# Filling in the data entries\n",
    "data_var = Variable(\n",
    "    \"data\", is_independent=False, is_binned=False, units=\"Number of jets\"\n",
    ")\n",
    "data_var.values = tab_data[\"hist_value\"]\n",
    "tab1d.add_variable(data_var)\n",
    "\n",
    "# Fill and example MC entry with uncertainty\n",
    "fqcd_var = Variable(\n",
    "    \"QCD (MC) forward region\",\n",
    "    is_independent=False,\n",
    "    is_binned=False,\n",
    "    units=\"Number of jets\",\n",
    ")\n",
    "fqcd_var.values = tab_fqcd[\"hist_value\"]\n",
    "fqcd_stat = Uncertainty(\"statistical uncertainty\", is_symmetric=False)\n",
    "s, s2 = tab_fqcd[\"hist_value\"], tab_fqcd[\"hist_variance\"]\n",
    "lo, up = hist.intervals.poisson_interval(s, s2)\n",
    "lo, up = lo - s, up - s\n",
    "fqcd_stat.values = zip(lo, up)\n",
    "fqcd_var.add_uncertainty(fqcd_stat)\n",
    "tab1d.add_variable(fqcd_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the readability of uncertainty variable declaration, the `hist_utils`\n",
    "package also provides, `hist_as_variable` method to easily declare variables.\n",
    "Uncertainties should be provided using a dictionary, with the dictionary keys\n",
    "being the desired name of the uncertainty, and the dictionary values being how\n",
    "the uncertainties should be defined. This can either be a string indicating how\n",
    "the uncertainty should be calculated (`poisson_sym` or `poisson_asym`), a\n",
    "floating point (pair) to indicate flat, a histogram (pair) of the same format as\n",
    "the input histogram representing the uncertainty, or a numpy array (pair) the is\n",
    "compatible with the final array output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepdata_lib.hist_utils import hist_as_variable\n",
    "\n",
    "tt_b_var = hist_as_variable(\n",
    "    \"ttbar b jets\",\n",
    "    tt_b_hist,\n",
    "    uncertainty={\n",
    "        \"statistical\": \"poisson_sym\",\n",
    "        \"flat symmetric uncertainty\": 0.1,\n",
    "        \"flat asymmetric uncertainty\": (-0.02, +0.03),\n",
    "        \"asymmetric uncertainty from histogram\": (\n",
    "            tt_l_hist * (-0.02),\n",
    "            tt_l_hist * 0.03,\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "tab1d.add_variable(tt_b_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using N-dimensional histogram\n",
    "\n",
    "Because of the flexibility of the scikit-hep histogram syntax, the same\n",
    "functions can be used for the histograms of arbitrary dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0),\n",
      " (-3.0, -2.4000000953674316),\n",
      " (-2.4000000953674316, -1.7999999523162842),\n",
      " (-1.7999999523162842, -1.2000000476837158),\n",
      " (-1.2000000476837158, -0.6000000238418579),\n",
      " (-0.6000000238418579, 0.0),\n",
      " (0.0, 0.6000000238418579),\n",
      " (0.6000000238418579, 1.2000000476837158),\n",
      " (1.2000000476837158, 1.7999999523162842),\n",
      " (1.7999999523162842, 2.4000000953674316),\n",
      " (2.4000000953674316, 3.0)]\n",
      "[(0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (0.0, 50.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (50.0, 100.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (100.0, 150.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (150.0, 200.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (200.0, 250.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (250.0, 300.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (300.0, 350.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (350.0, 400.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (400.0, 450.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0),\n",
      " (450.0, 500.0)]\n",
      "[2352.885997494168,\n",
      " 1436.0465312747995,\n",
      " 901.3585896392703,\n",
      " 521.4980348086548,\n",
      " 326.68594679365975,\n",
      " 187.2891782175859,\n",
      " 113.02068861656905,\n",
      " 75.15056125542428,\n",
      " 47.01724073695788,\n",
      " 26.16249765200011,\n",
      " 3337.65943937246,\n",
      " 2001.3833327285988,\n",
      " 1227.3740919899087,\n",
      " 732.8873139005796,\n",
      " 454.6459298425066,\n",
      " 273.60353431970987,\n",
      " 160.8611621666072,\n",
      " 93.2455177923032,\n",
      " 64.96021954009372,\n",
      " 40.14572278946859,\n",
      " 4353.925370783382,\n",
      " 2656.9423552298053,\n",
      " 1600.3681711597922,\n",
      " 974.1876981312107,\n",
      " 604.2002012643347,\n",
      " 351.69386768124934,\n",
      " 219.17651481690288,\n",
      " 136.49593818594383,\n",
      " 69.54930142369487,\n",
      " 48.92216527423846,\n",
      " 5265.259449827214,\n",
      " 3185.7545288544884,\n",
      " 1952.6173664743417,\n",
      " 1195.4539254004978,\n",
      " 714.2399996911945,\n",
      " 429.0047072808521,\n",
      " 258.63774375711574,\n",
      " 160.30722350048407,\n",
      " 93.17174529437514,\n",
      " 54.65404985193262,\n",
      " 5762.878985235474,\n",
      " 3447.5961936220656,\n",
      " 2116.2119508775395,\n",
      " 1255.1371112893112,\n",
      " 766.9011904121128,\n",
      " 471.425591703124,\n",
      " 289.30090211682614,\n",
      " 178.6303354182191,\n",
      " 106.41833189279154,\n",
      " 63.339274634030176,\n",
      " 5742.48409887165,\n",
      " 3508.989939547986,\n",
      " 2124.1420020192577,\n",
      " 1286.0070547725638,\n",
      " 758.1320858653928,\n",
      " 474.30263108502834,\n",
      " 286.9950550275313,\n",
      " 172.30007553331933,\n",
      " 108.14586482139536,\n",
      " 58.69811717763708,\n",
      " 5246.646822536993,\n",
      " 3173.2917236305593,\n",
      " 1930.1436192710808,\n",
      " 1160.6594547327047,\n",
      " 699.9776703709774,\n",
      " 447.0821688454779,\n",
      " 269.52941831869117,\n",
      " 162.17659498213476,\n",
      " 104.48848662213993,\n",
      " 59.19042659581844,\n",
      " 4331.371145983571,\n",
      " 2658.6636362214645,\n",
      " 1630.9332823516997,\n",
      " 963.5812924886504,\n",
      " 589.2502427945581,\n",
      " 351.25494961835204,\n",
      " 207.43266281453003,\n",
      " 133.66916410420322,\n",
      " 79.42877062856357,\n",
      " 47.77303844769148,\n",
      " 3303.2749615042057,\n",
      " 2023.0093007644878,\n",
      " 1252.6880576225274,\n",
      " 759.5124714277591,\n",
      " 442.43143721219724,\n",
      " 263.8030144449162,\n",
      " 169.43083751921245,\n",
      " 94.68098144498353,\n",
      " 62.70235467086735,\n",
      " 37.53621385186871,\n",
      " 2343.8071420010037,\n",
      " 1447.2347647598267,\n",
      " 859.9348382399742,\n",
      " 513.7538696645245,\n",
      " 324.4418135977764,\n",
      " 200.39215034620742,\n",
      " 121.75540862660874,\n",
      " 69.19435682732906,\n",
      " 41.26420955846811,\n",
      " 29.43278901600365]\n"
     ]
    }
   ],
   "source": [
    "tab2d = Table(\"my table 2d\")\n",
    "\n",
    "\n",
    "data_hist = h[dict(dataset=\"data\", flavor=sum)]\n",
    "qcd_hist = h[dict(dataset=\"QCD\", flavor=sum)]\n",
    "tt_b_hist = h[dict(dataset=\"ttbar\", flavor=4j)]\n",
    "tt_l_hist = h[dict(dataset=\"ttbar\", flavor=0j)]\n",
    "\n",
    "tab_data = read_hist(data_hist)\n",
    "# tab_qcd = read_hist(qcd_hist) # No-longer required to be declared!\n",
    "# tab_tt_b = read_hist(tt_b_hist)\n",
    "# tab_tt_l = read_hist(tt_l_hist)\n",
    "\n",
    "pt_var = Variable(\"Jet pT\", is_independent=True, is_binned=True, units=\"GeV\")\n",
    "pt_var.values = tab_data[\"pt\"]\n",
    "tab2d.add_variable(pt_var)\n",
    "eta_var = Variable(\"Jet eta\", is_independent=True, is_binned=True)\n",
    "eta_var.values = tab_data[\"eta\"]\n",
    "tab2d.add_variable(eta_var)\n",
    "\n",
    "# Filling in the data entries\n",
    "data_var = Variable(\n",
    "    \"data\", is_independent=False, is_binned=False, units=\"Number of jets\"\n",
    ")\n",
    "data_var.values = tab_data[\"hist_value\"]\n",
    "tab2d.add_variable(data_var)\n",
    "\n",
    "## Fill QCD, just statistical uncertainty\n",
    "qcd_var = hist_as_variable(\n",
    "    \"QCD MC\", qcd_hist, uncertainty={\"statistical\": \"poisson_asym\"}\n",
    ")\n",
    "tab2d.add_variable(qcd_var)\n",
    "\n",
    "# Checking the ordering \n",
    "pprint.pprint(eta_var.values)\n",
    "pprint.pprint(pt_var.values)\n",
    "pprint.pprint(qcd_var.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further simply the construction of table from N-dimensional histograms, we\n",
    "provide a `create_hist_base_table` function such that the axes variables are\n",
    "automatically set up directly with table declaration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hepdata_lib.hist_utils import create_hist_base_table\n",
    "\n",
    "tab2d_v2 = create_hist_base_table(\n",
    "    \"my simplifed 2d table\",\n",
    "    data_hist,\n",
    "    axes_rename={\"pt\": \"Jet pT\", \"eta\": \"Jet eta\"},\n",
    "    axes_units={\"pt\": \"GeV\"},\n",
    ")\n",
    "\n",
    "tab2d_v2.add_variable(hist_as_variable(\"Data\", data_hist))\n",
    "tab2d_v2.add_variable(\n",
    "    hist_as_variable(\n",
    "        \"ttbar l jets\", tt_l_hist, uncertainty={\"statistical\": \"poisson_sym\"}\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting the submission\n",
    "\n",
    "Finally, we can add the table to the sumission and create the required files.\n",
    "Please refer to the [Getting started notebook](Getting_started.ipynb) for a\n",
    "complete example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.add_table(tab1d)\n",
    "submission.add_table(tab2d)\n",
    "submission.add_table(tab2d_v2)\n",
    "submission.create_files(\"example_output_hist\", remove_old=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
